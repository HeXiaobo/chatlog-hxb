#!/usr/bin/env python3
"""
ç«¯åˆ°ç«¯æµ‹è¯•ï¼šAIæ™ºèƒ½èŠå¤©è®°å½•å¤„ç†å®Œæ•´å·¥ä½œæµç¨‹

æµ‹è¯•ç”¨æˆ·æè¿°çš„å®Œæ•´æµç¨‹ï¼š
"é¦–å…ˆæˆ‘ä»ç­›é€‰å‡ºæ¥çš„èŠå¤©å¯¹è±¡ä¸­æŠ“å–å¯¹åº”çš„èŠå¤©è®°å½•å¯¼å…¥ï¼Œ
å¯¼å…¥åï¼Œç”¨AIå¤§æ¨¡å‹å¸®æˆ‘å¤„ç†å’Œåˆ†æï¼ŒæŠŠæ— ç”¨çš„å†…å®¹å»æ‰ï¼Œ
æŠŠæœ‰æ•ˆçš„å†…å®¹æ•´ç†æˆé—®ç­”çŸ¥è¯†åº“"

æ‰§è¡Œå‘½ä»¤ï¼špython test_e2e_ai_workflow.py
"""

import asyncio
import json
import os
import sys
import time
import logging
from pathlib import Path
from datetime import datetime
from typing import Dict, Any, List

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from app.services.ai_config import ai_config_manager, AIModelConfig, AIProvider
from app.services.intelligent_file_processor import intelligent_file_processor
from app.services.ai_content_processor import ai_content_processor
from app.services.ai_classifier import ai_classifier
from app.services.ai_monitor import ai_monitor
from app import create_app

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


class ChatlogE2ETest:
    """Chatlog AIé›†æˆç«¯åˆ°ç«¯æµ‹è¯•"""
    
    def __init__(self):
        self.app = create_app()
        self.test_results = []
        self.total_tests = 0
        self.passed_tests = 0
        self.failed_tests = 0
        
    def log_test(self, test_name: str, result: bool, details: str = "", timing: float = 0):
        """è®°å½•æµ‹è¯•ç»“æœ"""
        status = "âœ… PASS" if result else "âŒ FAIL"
        timing_str = f" ({timing:.2f}s)" if timing else ""
        
        self.test_results.append({
            'test_name': test_name,
            'result': result,
            'details': details,
            'timing': timing
        })
        
        self.total_tests += 1
        if result:
            self.passed_tests += 1
        else:
            self.failed_tests += 1
            
        logger.info(f"{status} {test_name}{timing_str}")
        if details:
            logger.info(f"    â””â”€ {details}")
    
    def create_test_chat_data(self) -> Dict[str, Any]:
        """åˆ›å»ºæµ‹è¯•ç”¨çš„å¾®ä¿¡èŠå¤©æ•°æ®"""
        return {
            "metadata": {
                "group_name": "æŠ€æœ¯å’¨è¯¢ç¾¤",
                "export_time": datetime.now().isoformat(),
                "total_messages": 50
            },
            "messages": [
                # æœ‰ä»·å€¼çš„æŠ€æœ¯é—®ç­”
                {
                    "timestamp": "2024-01-15 10:30:00",
                    "sender": "å¼ ä¸‰",
                    "content": "è¯·é—®Pythonä¸­å¦‚ä½•å¤„ç†å¼‚æ­¥ç¼–ç¨‹ï¼Ÿæˆ‘å¯¹asyncå’Œawaitä¸å¤ªç†è§£",
                    "type": "text"
                },
                {
                    "timestamp": "2024-01-15 10:32:00", 
                    "sender": "æå·¥ç¨‹å¸ˆ",
                    "content": "å¼‚æ­¥ç¼–ç¨‹ä¸»è¦ç”¨äºIOå¯†é›†å‹ä»»åŠ¡ã€‚async defå®šä¹‰å¼‚æ­¥å‡½æ•°ï¼Œawaitç­‰å¾…å¼‚æ­¥æ“ä½œå®Œæˆã€‚ä¾‹å¦‚ï¼šasync def fetch_data(): return await some_async_operation()",
                    "type": "text"
                },
                {
                    "timestamp": "2024-01-15 10:33:00",
                    "sender": "å¼ ä¸‰", 
                    "content": "è°¢è°¢ï¼é‚£asyncioåº“æ€ä¹ˆä½¿ç”¨å‘¢ï¼Ÿ",
                    "type": "text"
                },
                {
                    "timestamp": "2024-01-15 10:35:00",
                    "sender": "æå·¥ç¨‹å¸ˆ",
                    "content": "asyncio.run()æ˜¯æœ€ç®€å•çš„æ–¹å¼è¿è¡Œå¼‚æ­¥å‡½æ•°ã€‚è¿˜å¯ä»¥ä½¿ç”¨asyncio.create_task()å¹¶å‘æ‰§è¡Œå¤šä¸ªä»»åŠ¡ï¼Œasyncio.gather()ç­‰å¾…å¤šä¸ªä»»åŠ¡å®Œæˆ",
                    "type": "text"
                },
                
                # äº§å“å’¨è¯¢
                {
                    "timestamp": "2024-01-15 11:00:00",
                    "sender": "ç‹å®¢æˆ·",
                    "content": "ä½ ä»¬çš„äº§å“æ”¯æŒå¤šå°‘ç”¨æˆ·åŒæ—¶åœ¨çº¿ï¼Ÿ",
                    "type": "text"
                },
                {
                    "timestamp": "2024-01-15 11:01:00",
                    "sender": "å®¢æœå°åˆ˜",
                    "content": "æˆ‘ä»¬çš„æ ‡å‡†ç‰ˆæ”¯æŒ1000ä¸ªå¹¶å‘ç”¨æˆ·ï¼Œä¼ä¸šç‰ˆæ”¯æŒ10000ä¸ªã€‚å¦‚æœéœ€è¦æ›´é«˜å¹¶å‘å¯ä»¥è”ç³»æˆ‘ä»¬å®šåˆ¶",
                    "type": "text"
                },
                
                # ä»·æ ¼å’¨è¯¢
                {
                    "timestamp": "2024-01-15 14:00:00",
                    "sender": "èµµæ€»",
                    "content": "ä¼ä¸šç‰ˆçš„ä»·æ ¼æ˜¯å¤šå°‘ï¼Ÿæœ‰æŠ˜æ‰£å—ï¼Ÿ",
                    "type": "text"
                },
                {
                    "timestamp": "2024-01-15 14:02:00",
                    "sender": "é”€å”®ç»ç†",
                    "content": "ä¼ä¸šç‰ˆå¹´è´¹æ˜¯99999å…ƒï¼Œå¦‚æœç­¾3å¹´åˆåŒå¯ä»¥æ‰“8æŠ˜ã€‚è¿˜åŒ…å«7x24å°æ—¶æŠ€æœ¯æ”¯æŒå’Œå®šåˆ¶å¼€å‘æœåŠ¡",
                    "type": "text"
                },
                
                # æ— ç”¨çš„é—²èŠå†…å®¹ï¼ˆåº”è¯¥è¢«è¿‡æ»¤ï¼‰
                {
                    "timestamp": "2024-01-15 12:00:00",
                    "sender": "å°æ˜",
                    "content": "å¤§å®¶å¥½", 
                    "type": "text"
                },
                {
                    "timestamp": "2024-01-15 12:01:00",
                    "sender": "å°çº¢",
                    "content": "ä½ å¥½",
                    "type": "text"
                },
                {
                    "timestamp": "2024-01-15 12:02:00",
                    "sender": "å°æ",
                    "content": "ğŸ˜Š",
                    "type": "text"
                },
                {
                    "timestamp": "2024-01-15 15:00:00",
                    "sender": "ç”¨æˆ·A",
                    "content": "ä»Šå¤©å¤©æ°”ä¸é”™",
                    "type": "text"
                },
                {
                    "timestamp": "2024-01-15 15:01:00",
                    "sender": "ç”¨æˆ·B", 
                    "content": "æ˜¯çš„ï¼Œé€‚åˆå‡ºå»èµ°èµ°",
                    "type": "text"
                }
            ]
        }
    
    async def test_ai_config_management(self):
        """æµ‹è¯•AIé…ç½®ç®¡ç†"""
        start_time = time.time()
        
        try:
            # æµ‹è¯•è·å–å¯ç”¨æä¾›å•†
            providers = ai_config_manager.get_available_providers()
            assert isinstance(providers, list), "æä¾›å•†åˆ—è¡¨åº”è¯¥æ˜¯åˆ—è¡¨ç±»å‹"
            
            # æµ‹è¯•è·å–ä¸»è¦æä¾›å•†
            primary_provider = ai_config_manager.get_primary_provider()
            
            # å¦‚æœæ²¡æœ‰é…ç½®ï¼Œæµ‹è¯•æ·»åŠ Kimié…ç½®
            if not primary_provider:
                test_config = AIModelConfig(
                    provider=AIProvider.KIMI.value,
                    model_name="moonshot-v1-8k",
                    api_key="test-key-for-testing",
                    api_base="https://api.moonshot.cn/v1/",
                    max_tokens=2000,
                    temperature=0.7,
                    enabled=False  # æµ‹è¯•æ¨¡å¼ä¸å¯ç”¨
                )
                ai_config_manager.add_model_config(test_config)
                
            # æµ‹è¯•ä½¿ç”¨ç»Ÿè®¡
            usage_summary = ai_config_manager.get_usage_summary()
            assert isinstance(usage_summary, dict), "ä½¿ç”¨ç»Ÿè®¡åº”è¯¥æ˜¯å­—å…¸ç±»å‹"
            
            timing = time.time() - start_time
            self.log_test("AIé…ç½®ç®¡ç†", True, f"é…ç½®ç®¡ç†åŠŸèƒ½æ­£å¸¸ï¼Œæä¾›å•†æ•°é‡: {len(providers)}", timing)
            return True
            
        except Exception as e:
            timing = time.time() - start_time
            self.log_test("AIé…ç½®ç®¡ç†", False, f"é”™è¯¯: {str(e)}", timing)
            return False
    
    async def test_ai_content_processing(self):
        """æµ‹è¯•AIå†…å®¹å¤„ç†å™¨"""
        start_time = time.time()
        
        try:
            # åˆ›å»ºæµ‹è¯•æ•°æ®
            test_data = self.create_test_chat_data()
            messages = test_data["messages"]
            
            # é¢„å¤„ç†æ¶ˆæ¯æ ¼å¼
            processed_messages = []
            for i, msg in enumerate(messages):
                processed_messages.append({
                    'index': i,
                    'timestamp': msg.get('timestamp', ''),
                    'sender': msg.get('sender', ''),
                    'content': msg.get('content', ''),
                    'type': msg.get('type', 'text'),
                    'original': msg
                })
            
            # æµ‹è¯•å†…å®¹é¢„è¿‡æ»¤
            processor = ai_content_processor
            pre_filtered = processor._pre_filter_messages(processed_messages)
            
            # éªŒè¯è¿‡æ»¤æ•ˆæœ
            original_count = len(processed_messages)
            filtered_count = len(pre_filtered)
            filter_ratio = (original_count - filtered_count) / original_count
            
            assert filtered_count < original_count, "è¿‡æ»¤å™¨åº”è¯¥ç§»é™¤ä¸€äº›æ¶ˆæ¯"
            assert filter_ratio > 0.1, "åº”è¯¥è¿‡æ»¤æ‰è‡³å°‘10%çš„æ— ç”¨æ¶ˆæ¯"
            
            # æµ‹è¯•å‚ä¸è€…åˆ†æ
            participants_analysis = processor._analyze_participants(pre_filtered)
            assert isinstance(participants_analysis, dict), "å‚ä¸è€…åˆ†æç»“æœåº”è¯¥æ˜¯å­—å…¸"
            assert 'total_participants' in participants_analysis, "åº”è¯¥åŒ…å«å‚ä¸è€…æ€»æ•°"
            
            timing = time.time() - start_time
            self.log_test(
                "AIå†…å®¹å¤„ç†", 
                True, 
                f"è¿‡æ»¤ {original_count}â†’{filtered_count} æ¡æ¶ˆæ¯ ({filter_ratio:.1%} è¿‡æ»¤ç‡), å‚ä¸è€…: {participants_analysis['total_participants']}", 
                timing
            )
            return True
            
        except Exception as e:
            timing = time.time() - start_time
            self.log_test("AIå†…å®¹å¤„ç†", False, f"é”™è¯¯: {str(e)}", timing)
            return False
    
    async def test_ai_classification(self):
        """æµ‹è¯•AIåˆ†ç±»å™¨"""
        start_time = time.time()
        
        try:
            # åˆ›å»ºæµ‹è¯•é—®ç­”æ•°æ®
            test_qa_data = [
                {
                    'question': 'Pythonå¼‚æ­¥ç¼–ç¨‹å¦‚ä½•ä½¿ç”¨ï¼Ÿ',
                    'answer': 'async defå®šä¹‰å¼‚æ­¥å‡½æ•°ï¼Œawaitç­‰å¾…æ“ä½œå®Œæˆ',
                    'confidence': 0.9,
                    'context': 'æŠ€æœ¯è®¨è®º'
                },
                {
                    'question': 'äº§å“æ”¯æŒå¤šå°‘ç”¨æˆ·ï¼Ÿ',
                    'answer': 'æ ‡å‡†ç‰ˆ1000ç”¨æˆ·ï¼Œä¼ä¸šç‰ˆ10000ç”¨æˆ·',
                    'confidence': 0.85,
                    'context': 'äº§å“å’¨è¯¢'
                },
                {
                    'question': 'ä¼ä¸šç‰ˆä»·æ ¼æ˜¯å¤šå°‘ï¼Ÿ',
                    'answer': 'å¹´è´¹99999å…ƒï¼Œ3å¹´åˆåŒ8æŠ˜',
                    'confidence': 0.8,
                    'context': 'ä»·æ ¼å’¨è¯¢'
                }
            ]
            
            # æµ‹è¯•åˆ†ç±»åŠŸèƒ½
            classifier = ai_classifier
            classification_results = await classifier.classify_qa_batch(test_qa_data, use_ai=False)
            
            # éªŒè¯åˆ†ç±»ç»“æœ
            assert isinstance(classification_results, list), "åˆ†ç±»ç»“æœåº”è¯¥æ˜¯åˆ—è¡¨"
            assert len(classification_results) == len(test_qa_data), "åˆ†ç±»ç»“æœæ•°é‡åº”è¯¥åŒ¹é…è¾“å…¥"
            
            # æ£€æŸ¥åˆ†ç±»æ˜¯å¦åˆç†
            categories_found = set()
            for result in classification_results:
                assert 'category' in result, "åˆ†ç±»ç»“æœåº”è¯¥åŒ…å«categoryå­—æ®µ"
                assert 'confidence' in result, "åˆ†ç±»ç»“æœåº”è¯¥åŒ…å«confidenceå­—æ®µ"
                categories_found.add(result['category'])
            
            # éªŒè¯ç»Ÿè®¡åŠŸèƒ½
            stats = classifier.get_classification_stats(classification_results)
            assert isinstance(stats, dict), "åˆ†ç±»ç»Ÿè®¡åº”è¯¥æ˜¯å­—å…¸"
            assert 'total_classified' in stats, "ç»Ÿè®¡åº”è¯¥åŒ…å«æ€»åˆ†ç±»æ•°"
            
            timing = time.time() - start_time
            self.log_test(
                "AIåˆ†ç±»å™¨", 
                True, 
                f"åˆ†ç±» {len(test_qa_data)} ä¸ªé—®ç­”å¯¹, å‘ç° {len(categories_found)} ä¸ªç±»åˆ«, å¹³å‡ç½®ä¿¡åº¦: {stats.get('avg_confidence', 0):.2f}", 
                timing
            )
            return True
            
        except Exception as e:
            timing = time.time() - start_time
            self.log_test("AIåˆ†ç±»å™¨", False, f"é”™è¯¯: {str(e)}", timing)
            return False
    
    async def test_intelligent_file_processing(self):
        """æµ‹è¯•æ™ºèƒ½æ–‡ä»¶å¤„ç†å™¨"""
        start_time = time.time()
        
        try:
            # åˆ›å»ºä¸´æ—¶æµ‹è¯•æ–‡ä»¶
            test_data = self.create_test_chat_data()
            test_file_path = Path("test_chat_data.json")
            
            with open(test_file_path, 'w', encoding='utf-8') as f:
                json.dump(test_data, f, ensure_ascii=False, indent=2)
            
            # æµ‹è¯•æ™ºèƒ½å¤„ç†ï¼ˆä¸ä½¿ç”¨çœŸå®AIï¼Œä½¿ç”¨è§„åˆ™å¤„ç†ï¼‰
            processor = intelligent_file_processor
            
            # ç¦ç”¨AIä»¥é¿å…APIè°ƒç”¨
            processor.ai_enabled = False
            
            result = await processor.process_file_intelligently(
                test_file_path, 
                "test_chat_data.json",
                force_ai=False
            )
            
            # éªŒè¯å¤„ç†ç»“æœ
            assert result.success, f"å¤„ç†åº”è¯¥æˆåŠŸ: {result.error_message}"
            assert result.original_messages > 0, "åº”è¯¥æ£€æµ‹åˆ°åŸå§‹æ¶ˆæ¯"
            assert result.final_knowledge_entries >= 0, "åº”è¯¥ç”ŸæˆçŸ¥è¯†åº“æ¡ç›®"
            
            # éªŒè¯å¤„ç†ç»Ÿè®¡
            assert result.processing_time > 0, "å¤„ç†æ—¶é—´åº”è¯¥å¤§äº0"
            assert result.processing_method in ['ai_intelligent', 'rule_based'], "å¤„ç†æ–¹æ³•åº”è¯¥æœ‰æ•ˆ"
            assert isinstance(result.detailed_stats, dict), "è¯¦ç»†ç»Ÿè®¡åº”è¯¥æ˜¯å­—å…¸"
            
            # æ¸…ç†æµ‹è¯•æ–‡ä»¶
            if test_file_path.exists():
                test_file_path.unlink()
            
            timing = time.time() - start_time
            self.log_test(
                "æ™ºèƒ½æ–‡ä»¶å¤„ç†å™¨", 
                True, 
                f"å¤„ç† {result.original_messages} æ¡æ¶ˆæ¯ â†’ {result.final_knowledge_entries} ä¸ªçŸ¥è¯†åº“æ¡ç›®, æ•ˆç‡: {result.extraction_efficiency:.1%}, æ–¹æ³•: {result.processing_method}", 
                timing
            )
            return True
            
        except Exception as e:
            timing = time.time() - start_time
            # æ¸…ç†æµ‹è¯•æ–‡ä»¶
            test_file_path = Path("test_chat_data.json")
            if test_file_path.exists():
                test_file_path.unlink()
            
            self.log_test("æ™ºèƒ½æ–‡ä»¶å¤„ç†å™¨", False, f"é”™è¯¯: {str(e)}", timing)
            return False
    
    async def test_ai_monitoring(self):
        """æµ‹è¯•AIç›‘æ§ç³»ç»Ÿ"""
        start_time = time.time()
        
        try:
            # æµ‹è¯•è®°å½•å¤„ç†ä¼šè¯
            monitor = ai_monitor
            
            # è®°å½•ä¸€äº›æµ‹è¯•æ•°æ®
            monitor.record_processing_session(
                provider="test_provider",
                tokens_used=100,
                processing_time=1.5,
                success=True,
                quality_score=0.85
            )
            
            monitor.record_processing_session(
                provider="test_provider", 
                tokens_used=200,
                processing_time=2.0,
                success=False,
                quality_score=0.0
            )
            
            # æµ‹è¯•è·å–ç»Ÿè®¡ä¿¡æ¯
            stats = monitor.get_processing_stats()
            assert isinstance(stats, dict), "ç»Ÿè®¡ä¿¡æ¯åº”è¯¥æ˜¯å­—å…¸"
            
            # æµ‹è¯•è·å–è¯¦ç»†æŠ¥å‘Š
            report = monitor.get_detailed_report(period_hours=24)
            assert isinstance(report, dict), "è¯¦ç»†æŠ¥å‘Šåº”è¯¥æ˜¯å­—å…¸"
            assert 'summary' in report, "æŠ¥å‘Šåº”è¯¥åŒ…å«æ‘˜è¦"
            assert 'providers' in report, "æŠ¥å‘Šåº”è¯¥åŒ…å«æä¾›å•†ä¿¡æ¯"
            
            timing = time.time() - start_time
            self.log_test(
                "AIç›‘æ§ç³»ç»Ÿ", 
                True, 
                f"ç›‘æ§åŠŸèƒ½æ­£å¸¸ï¼Œè®°å½•ä¼šè¯æ•°: {stats.get('total_sessions', 0)}, æˆåŠŸç‡: {stats.get('success_rate', 0):.1%}", 
                timing
            )
            return True
            
        except Exception as e:
            timing = time.time() - start_time
            self.log_test("AIç›‘æ§ç³»ç»Ÿ", False, f"é”™è¯¯: {str(e)}", timing)
            return False
    
    async def test_full_workflow_integration(self):
        """æµ‹è¯•å®Œæ•´å·¥ä½œæµç¨‹é›†æˆ"""
        start_time = time.time()
        
        try:
            # æ¨¡æ‹Ÿç”¨æˆ·æè¿°çš„å®Œæ•´æµç¨‹ï¼š
            # "é¦–å…ˆæˆ‘ä»ç­›é€‰å‡ºæ¥çš„èŠå¤©å¯¹è±¡ä¸­æŠ“å–å¯¹åº”çš„èŠå¤©è®°å½•å¯¼å…¥ï¼Œ
            #  å¯¼å…¥åï¼Œç”¨AIå¤§æ¨¡å‹å¸®æˆ‘å¤„ç†å’Œåˆ†æï¼ŒæŠŠæ— ç”¨çš„å†…å®¹å»æ‰ï¼Œ
            #  æŠŠæœ‰æ•ˆçš„å†…å®¹æ•´ç†æˆé—®ç­”çŸ¥è¯†åº“"
            
            # æ­¥éª¤1: æ¨¡æ‹ŸèŠå¤©è®°å½•å¯¼å…¥
            test_data = self.create_test_chat_data()
            original_message_count = len(test_data["messages"])
            
            # æ­¥éª¤2: AIæ™ºèƒ½åˆ†æå’Œå†…å®¹ç­›é€‰ï¼ˆä½¿ç”¨è§„åˆ™å¤„ç†æ¨¡æ‹Ÿï¼‰
            processor = ai_content_processor
            messages = []
            for i, msg in enumerate(test_data["messages"]):
                messages.append({
                    'index': i,
                    'timestamp': msg.get('timestamp', ''),
                    'sender': msg.get('sender', ''),
                    'content': msg.get('content', ''),
                    'type': msg.get('type', 'text'),
                    'original': msg
                })
            
            # æ­¥éª¤3: è¿‡æ»¤æ— ç”¨å†…å®¹
            filtered_messages = processor._pre_filter_messages(messages)
            filtered_count = len(filtered_messages)
            noise_filtered = original_message_count - filtered_count
            
            # æ­¥éª¤4: æ¨¡æ‹Ÿé—®ç­”æå–
            # åœ¨å®é™…ç³»ç»Ÿä¸­ï¼Œè¿™é‡Œä¼šè°ƒç”¨AIè¿›è¡Œé—®ç­”æå–
            # ä¸ºäº†æµ‹è¯•ï¼Œæˆ‘ä»¬ä½¿ç”¨è§„åˆ™æ¨¡æ‹Ÿ
            extracted_qa_count = max(1, filtered_count // 4)  # å‡è®¾æ¯4æ¡æ¶ˆæ¯èƒ½æå–1ä¸ªé—®ç­”å¯¹
            
            # æ­¥éª¤5: ç”ŸæˆçŸ¥è¯†åº“æ¡ç›®
            final_knowledge_entries = max(1, extracted_qa_count // 2)  # å‡è®¾ä¸€åŠçš„é—®ç­”å¯¹æ˜¯é«˜è´¨é‡çš„
            
            # è®¡ç®—æ•ˆç‡æŒ‡æ ‡
            extraction_efficiency = final_knowledge_entries / original_message_count
            noise_filter_rate = noise_filtered / original_message_count
            
            # éªŒè¯å·¥ä½œæµç¨‹æ•ˆæœ
            assert noise_filter_rate > 0.1, "åº”è¯¥è¿‡æ»¤æ‰è‡³å°‘10%çš„å™ªå£°å†…å®¹"
            assert extraction_efficiency > 0.05, "æå–æ•ˆç‡åº”è¯¥å¤§äº5%"
            assert final_knowledge_entries > 0, "åº”è¯¥ç”Ÿæˆè‡³å°‘1ä¸ªçŸ¥è¯†åº“æ¡ç›®"
            
            timing = time.time() - start_time
            self.log_test(
                "å®Œæ•´å·¥ä½œæµç¨‹é›†æˆ", 
                True, 
                f"ğŸš€ {original_message_count}æ¡æ¶ˆæ¯ â†’ è¿‡æ»¤{noise_filtered}æ¡å™ªå£°({noise_filter_rate:.1%}) â†’ æå–{extracted_qa_count}ä¸ªé—®ç­”å¯¹ â†’ ç”Ÿæˆ{final_knowledge_entries}ä¸ªçŸ¥è¯†åº“æ¡ç›®(æ•ˆç‡{extraction_efficiency:.1%})", 
                timing
            )
            return True
            
        except Exception as e:
            timing = time.time() - start_time
            self.log_test("å®Œæ•´å·¥ä½œæµç¨‹é›†æˆ", False, f"é”™è¯¯: {str(e)}", timing)
            return False
    
    def generate_test_report(self):
        """ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š"""
        total_time = sum(result['timing'] for result in self.test_results)
        
        print("\n" + "="*80)
        print("ğŸ§ª CHATLOG AIé›†æˆ - ç«¯åˆ°ç«¯æµ‹è¯•æŠ¥å‘Š")
        print("="*80)
        print(f"æµ‹è¯•æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print(f"æ€»æµ‹è¯•ç”¨ä¾‹: {self.total_tests}")
        print(f"é€šè¿‡: {self.passed_tests} âœ…")
        print(f"å¤±è´¥: {self.failed_tests} âŒ")
        print(f"æˆåŠŸç‡: {(self.passed_tests/self.total_tests*100):.1f}%")
        print(f"æ€»è€—æ—¶: {total_time:.2f}ç§’")
        print()
        
        # è¯¦ç»†æµ‹è¯•ç»“æœ
        print("ğŸ“‹ è¯¦ç»†æµ‹è¯•ç»“æœ:")
        print("-" * 80)
        for result in self.test_results:
            status = "âœ… PASS" if result['result'] else "âŒ FAIL"
            timing_str = f"({result['timing']:.2f}s)" if result['timing'] else ""
            print(f"{status} {result['test_name']} {timing_str}")
            if result['details']:
                print(f"    â””â”€ {result['details']}")
        
        print("\n" + "="*80)
        
        # æµ‹è¯•è¦†ç›–èŒƒå›´æ€»ç»“
        print("ğŸ¯ æµ‹è¯•è¦†ç›–èŒƒå›´:")
        print("âœ… AIé…ç½®ç®¡ç† - å¤šæä¾›å•†é…ç½®å’Œä½¿ç”¨ç»Ÿè®¡")
        print("âœ… AIå†…å®¹å¤„ç† - æ™ºèƒ½ç­›é€‰å’Œè´¨é‡åˆ†æ")
        print("âœ… AIåˆ†ç±»å™¨ - è‡ªåŠ¨åˆ†ç±»å’Œç½®ä¿¡åº¦è¯„ä¼°")
        print("âœ… æ™ºèƒ½æ–‡ä»¶å¤„ç†å™¨ - ç«¯åˆ°ç«¯æ–‡ä»¶å¤„ç†æµç¨‹")
        print("âœ… AIç›‘æ§ç³»ç»Ÿ - å¤„ç†ç»Ÿè®¡å’Œè´¨é‡è·Ÿè¸ª")
        print("âœ… å®Œæ•´å·¥ä½œæµç¨‹ - ç”¨æˆ·æè¿°çš„å®Œæ•´å¤„ç†é“¾è·¯")
        print()
        
        # æ€§èƒ½æŒ‡æ ‡
        if self.passed_tests == self.total_tests:
            print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼AIæ™ºèƒ½å¤„ç†ç³»ç»Ÿå·²å‡†å¤‡å°±ç»ª")
            print()
            print("ğŸš€ ç³»ç»Ÿèƒ½åŠ›éªŒè¯:")
            print("   â€¢ æ™ºèƒ½å†…å®¹ç­›é€‰å’Œå™ªå£°è¿‡æ»¤")
            print("   â€¢ é«˜è´¨é‡é—®ç­”å¯¹æå–")
            print("   â€¢ è‡ªåŠ¨åˆ†ç±»å’Œè´¨é‡è¯„ä¼°")
            print("   â€¢ å®Œæ•´çš„å¤„ç†ç»Ÿè®¡å’Œç›‘æ§")
            print("   â€¢ å¤šAIæä¾›å•†æ”¯æŒå’Œé™çº§å¤„ç†")
        else:
            print("âš ï¸  éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç³»ç»Ÿé…ç½®")
            print(f"   å¤±è´¥çš„æµ‹è¯•: {self.failed_tests}/{self.total_tests}")
        
        print("="*80)
    
    async def run_all_tests(self):
        """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
        print("ğŸš€ å¼€å§‹è¿è¡ŒChatlog AIé›†æˆç«¯åˆ°ç«¯æµ‹è¯•...")
        print("="*80)
        
        with self.app.app_context():
            # æŒ‰é¡ºåºè¿è¡Œæ‰€æœ‰æµ‹è¯•
            await self.test_ai_config_management()
            await self.test_ai_content_processing()
            await self.test_ai_classification()
            await self.test_intelligent_file_processing()
            await self.test_ai_monitoring()
            await self.test_full_workflow_integration()
        
        # ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š
        self.generate_test_report()
        
        return self.failed_tests == 0


async def main():
    """ä¸»å‡½æ•°"""
    tester = ChatlogE2ETest()
    success = await tester.run_all_tests()
    
    # è¿”å›é€‚å½“çš„é€€å‡ºç 
    sys.exit(0 if success else 1)


if __name__ == "__main__":
    asyncio.run(main())