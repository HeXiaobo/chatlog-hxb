"""
æ–‡ä»¶ä¸Šä¼ ç›¸å…³è·¯ç”± - æ”¯æŒå¼‚æ­¥å¤„ç†å’Œå®æ—¶çŠ¶æ€æ›´æ–°
"""
from flask import Blueprint, jsonify, request, current_app
from werkzeug.utils import secure_filename
import os
import logging
from datetime import datetime
from pathlib import Path
from app import db
from app.models import UploadHistory
from app.services import FileProcessor
from app.services.ai_file_processor import AIFileProcessor
from app.services.intelligent_file_processor import intelligent_file_processor
from app.services.task_queue import get_file_processing_service, TaskPriority
from app.services.websocket_service import get_websocket_manager

logger = logging.getLogger(__name__)
upload_bp = Blueprint('upload', __name__)


@upload_bp.route('/file', methods=['POST'])
def upload_file():
    """ä¸Šä¼ å¹¶å¤„ç†å¾®ä¿¡èŠå¤©è®°å½•JSONæ–‡ä»¶"""
    try:
        # æ£€æŸ¥æ–‡ä»¶
        if 'file' not in request.files:
            return jsonify({
                'success': False,
                'error': {
                    'code': 'NO_FILE',
                    'message': 'æœªé€‰æ‹©æ–‡ä»¶',
                    'details': 'è¯·é€‰æ‹©è¦ä¸Šä¼ çš„JSONæ–‡ä»¶'
                }
            }), 400
        
        file = request.files['file']
        if not file.filename:
            return jsonify({
                'success': False,
                'error': {
                    'code': 'EMPTY_FILENAME',
                    'message': 'æ–‡ä»¶åä¸ºç©º',
                    'details': 'è¯·é€‰æ‹©æœ‰æ•ˆçš„æ–‡ä»¶'
                }
            }), 400
        
        # ä¿å­˜ä¸Šä¼ çš„æ–‡ä»¶
        original_filename = file.filename
        filename = secure_filename(original_filename)
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        filename = f"{timestamp}_{filename}"
        
        upload_folder = Path(current_app.config['UPLOAD_FOLDER'])
        upload_folder.mkdir(exist_ok=True)
        file_path = upload_folder / filename
        
        # ä¿å­˜æ–‡ä»¶
        file.save(str(file_path))
        logger.info(f"File saved: {file_path}")
        
        # å¼ºåˆ¶è°ƒè¯•è¾“å‡º
        print(f"[UPLOAD-DEBUG] File received: {original_filename}")
        print(f"[UPLOAD-DEBUG] File size: {file_path.stat().st_size} bytes")
        print(f"[UPLOAD-DEBUG] Saved to: {file_path}")
        
        # è°ƒè¯•ï¼šå¤‡ä»½å‰ç«¯å‘é€çš„æ–‡ä»¶ç”¨äºåˆ†æ
        debug_path = file_path.parent / f"debug_{filename}"
        try:
            import shutil
            shutil.copy2(file_path, debug_path)
            print(f"[UPLOAD-DEBUG] Debug copy saved: {debug_path}")
            logger.info(f"Debug copy saved: {debug_path}")
        except Exception as e:
            print(f"[UPLOAD-DEBUG] Failed to create debug copy: {e}")
        
        # è·å–å¤„ç†é€‰é¡¹
        use_ai = request.form.get('use_ai', 'true').lower() == 'true'
        processing_mode = request.form.get('processing_mode', 'standard')  # 'standard' æˆ– 'intelligent'
        
        # é€‰æ‹©å¤„ç†å™¨
        if processing_mode == 'intelligent':
            # ä½¿ç”¨æ–°çš„æ™ºèƒ½å¤„ç†å™¨
            import asyncio
            result_obj = asyncio.run(intelligent_file_processor.process_file_intelligently(
                file_path, original_filename, force_ai=use_ai
            ))
            
            # è½¬æ¢ä¸ºå…¼å®¹æ ¼å¼
            result = {
                'success': result_obj.success,
                'upload_id': result_obj.upload_id,
                'total_extracted': result_obj.qa_pairs_extracted,
                'total_saved': result_obj.final_knowledge_entries,
                'processing_time': result_obj.processing_time,
                'processing_method': result_obj.processing_method,
                'ai_enabled': result_obj.ai_enabled,
                'statistics': {
                    'original_messages': result_obj.original_messages,
                    'useful_messages': result_obj.useful_messages,
                    'noise_filtered': result_obj.noise_filtered,
                    'extraction_efficiency': result_obj.extraction_efficiency,
                    'content_improvement_rate': result_obj.content_improvement_rate,
                    'ai_provider_used': result_obj.ai_provider_used,
                    'tokens_consumed': result_obj.tokens_consumed,
                    'processing_cost': result_obj.processing_cost
                },
                'message': f'æ™ºèƒ½å¤„ç†å®Œæˆ! ä»{result_obj.original_messages}æ¡æ¶ˆæ¯ä¸­ç”Ÿæˆ{result_obj.final_knowledge_entries}ä¸ªé«˜è´¨é‡çŸ¥è¯†åº“æ¡ç›®',
                'error': result_obj.error_message
            }
        elif use_ai:
            processor = AIFileProcessor()
            result = processor.process_file_async_with_ai(file_path, original_filename, use_ai=True)
        else:
            processor = FileProcessor()
            result = processor.process_file_async(file_path, original_filename)
        
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶ï¼ˆä»…åœ¨æˆåŠŸæ—¶æ¸…ç†ï¼‰
        try:
            if result['success']:
                file_path.unlink()
                print(f"[UPLOAD-DEBUG] Cleaned up temp file: {file_path}")
            else:
                print(f"[UPLOAD-DEBUG] Keeping failed file for analysis: {file_path}")
        except Exception as e:
            print(f"[UPLOAD-DEBUG] Failed to clean temp file: {str(e)}")
            logger.warning(f"Failed to remove temp file {file_path}: {str(e)}")
        
        # è¿”å›å¤„ç†ç»“æœ
        if result['success']:
            response_data = {
                'success': True,
                'data': {
                    'upload_id': result['upload_id'],
                    'filename': original_filename,
                    'total_extracted': result.get('total_extracted', 0),
                    'total_saved': result.get('total_saved', 0),
                    'processing_time': result.get('processing_time', 0),
                    'statistics': result.get('statistics', {})
                },
                'message': result.get('message', 'æ–‡ä»¶å¤„ç†å®Œæˆ')
            }
            
            return jsonify(response_data), 200
        else:
            return jsonify({
                'success': False,
                'error': {
                    'code': 'PROCESSING_ERROR',
                    'message': 'æ–‡ä»¶å¤„ç†å¤±è´¥',
                    'details': result.get('error', 'æœªçŸ¥é”™è¯¯')
                }
            }), 400
            
    except Exception as e:
        logger.error(f"Upload file error: {str(e)}")
        return jsonify({
            'success': False,
            'error': {
                'code': 'UPLOAD_ERROR',
                'message': 'æ–‡ä»¶ä¸Šä¼ å¤±è´¥',
                'details': str(e)
            }
        }), 500


@upload_bp.route('/status/<int:upload_id>')
def get_upload_status(upload_id):
    """è·å–ä¸Šä¼ å¤„ç†çŠ¶æ€"""
    try:
        processor = FileProcessor()
        result = processor.get_processing_status(upload_id)
        
        if result['success']:
            return jsonify({
                'success': True,
                'data': {
                    'upload_id': result['upload_id'],
                    'filename': result['filename'],
                    'status': result['status'],
                    'qa_count': result['qa_count'],
                    'processing_time': result['processing_time'],
                    'uploaded_at': result['uploaded_at'],
                    'completed_at': result['completed_at'],
                    'error_message': result['error_message']
                },
                'message': 'çŠ¶æ€è·å–æˆåŠŸ'
            }), 200
        else:
            return jsonify({
                'success': False,
                'error': {
                    'code': 'NOT_FOUND',
                    'message': result['error']
                }
            }), 404
            
    except Exception as e:
        logger.error(f"Get upload status error: {str(e)}")
        return jsonify({
            'success': False,
            'error': {
                'code': 'STATUS_ERROR',
                'message': 'è·å–çŠ¶æ€å¤±è´¥',
                'details': str(e)
            }
        }), 500


@upload_bp.route('/history')
def get_upload_history():
    """è·å–ä¸Šä¼ å†å²è®°å½•"""
    try:
        page = request.args.get('page', 1, type=int)
        per_page = request.args.get('per_page', 20, type=int)
        status = request.args.get('status')
        
        # æ„å»ºæŸ¥è¯¢
        query = UploadHistory.query
        
        # çŠ¶æ€ç­›é€‰
        if status and status in ['processing', 'completed', 'failed']:
            query = query.filter_by(status=status)
        
        # åˆ†é¡µæŸ¥è¯¢
        pagination = query.order_by(UploadHistory.uploaded_at.desc()).paginate(
            page=page,
            per_page=min(per_page, 100),
            error_out=False
        )
        
        # è½¬æ¢æ•°æ®
        history_data = []
        for record in pagination.items:
            history_data.append({
                'id': record.id,
                'filename': record.filename,
                'file_size': record.file_size,
                'status': record.status,
                'qa_count': record.qa_count or 0,
                'processing_time': record.processing_time,
                'uploaded_at': record.uploaded_at.isoformat() if record.uploaded_at else None,
                'completed_at': record.completed_at.isoformat() if record.completed_at else None,
                'error_message': record.error_message
            })
        
        return jsonify({
            'success': True,
            'data': history_data,
            'pagination': {
                'page': pagination.page,
                'per_page': pagination.per_page,
                'total': pagination.total,
                'pages': pagination.pages
            },
            'message': 'ä¸Šä¼ å†å²è·å–æˆåŠŸ'
        }), 200
        
    except Exception as e:
        logger.error(f"Get upload history error: {str(e)}")
        return jsonify({
            'success': False,
            'error': {
                'code': 'HISTORY_ERROR',
                'message': 'è·å–ä¸Šä¼ å†å²å¤±è´¥',
                'details': str(e)
            }
        }), 500


@upload_bp.route('/cleanup', methods=['POST'])
def cleanup_files():
    """æ¸…ç†ä¸´æ—¶æ–‡ä»¶"""
    try:
        max_age_hours = request.json.get('max_age_hours', 24) if request.json else 24
        
        processor = FileProcessor()
        cleaned_count = processor.cleanup_temp_files(max_age_hours)
        
        return jsonify({
            'success': True,
            'data': {
                'cleaned_files': cleaned_count
            },
            'message': f'æ¸…ç†äº† {cleaned_count} ä¸ªä¸´æ—¶æ–‡ä»¶'
        }), 200
        
    except Exception as e:
        logger.error(f"Cleanup files error: {str(e)}")
        return jsonify({
            'success': False,
            'error': {
                'code': 'CLEANUP_ERROR',
                'message': 'æ¸…ç†æ–‡ä»¶å¤±è´¥',
                'details': str(e)
            }
        }), 500


@upload_bp.route('/ai/capabilities')
def get_ai_capabilities():
    """è·å–AIå¤„ç†èƒ½åŠ›ä¿¡æ¯"""
    try:
        processor = AIFileProcessor()
        capabilities = processor.get_ai_processing_capabilities()
        
        return jsonify({
            'success': True,
            'data': capabilities,
            'message': 'AIèƒ½åŠ›ä¿¡æ¯è·å–æˆåŠŸ'
        }), 200
        
    except Exception as e:
        logger.error(f"Get AI capabilities error: {str(e)}")
        return jsonify({
            'success': False,
            'error': {
                'code': 'AI_CAPABILITIES_ERROR',
                'message': 'è·å–AIèƒ½åŠ›ä¿¡æ¯å¤±è´¥',
                'details': str(e)
            }
        }), 500


@upload_bp.route('/ai/enhance', methods=['POST'])
def enhance_existing_qa():
    """ä½¿ç”¨AIå¢å¼ºç°æœ‰çš„ä½è´¨é‡é—®ç­”å¯¹"""
    try:
        import asyncio
        limit = request.json.get('limit', 100) if request.json else 100
        
        processor = AIFileProcessor()
        result = asyncio.run(processor.enhance_existing_qa_pairs(limit))
        
        if result['success']:
            return jsonify({
                'success': True,
                'data': {
                    'enhanced_count': result['enhanced_count'],
                    'total_processed': result.get('total_processed', 0)
                },
                'message': result['message']
            }), 200
        else:
            return jsonify({
                'success': False,
                'error': {
                    'code': 'AI_ENHANCE_ERROR',
                    'message': result['error']
                }
            }), 400
            
    except Exception as e:
        logger.error(f"Enhance existing QA error: {str(e)}")
        return jsonify({
            'success': False,
            'error': {
                'code': 'ENHANCE_ERROR',
                'message': 'AIå¢å¼ºå¤±è´¥',
                'details': str(e)
            }
        }), 500


@upload_bp.route('/ai/usage')
def get_ai_usage():
    """è·å–AIä½¿ç”¨ç»Ÿè®¡"""
    try:
        processor = AIFileProcessor()
        usage_summary = processor.get_ai_usage_summary()
        
        return jsonify({
            'success': True,
            'data': usage_summary,
            'message': 'AIä½¿ç”¨ç»Ÿè®¡è·å–æˆåŠŸ'
        }), 200
        
    except Exception as e:
        logger.error(f"Get AI usage error: {str(e)}")
        return jsonify({
            'success': False,
            'error': {
                'code': 'AI_USAGE_ERROR',
                'message': 'è·å–AIä½¿ç”¨ç»Ÿè®¡å¤±è´¥',
                'details': str(e)
            }
        }), 500


@upload_bp.route('/file/ai', methods=['POST'])
def upload_file_with_ai():
    """ä½¿ç”¨AIå¤„ç†çš„æ–‡ä»¶ä¸Šä¼ æ¥å£"""
    try:
        # æ£€æŸ¥æ–‡ä»¶
        if 'file' not in request.files:
            return jsonify({
                'success': False,
                'error': {
                    'code': 'NO_FILE',
                    'message': 'æœªé€‰æ‹©æ–‡ä»¶'
                }
            }), 400
        
        file = request.files['file']
        if not file.filename:
            return jsonify({
                'success': False,
                'error': {
                    'code': 'EMPTY_FILENAME',
                    'message': 'æ–‡ä»¶åä¸ºç©º'
                }
            }), 400
        
        # ä¿å­˜æ–‡ä»¶
        original_filename = file.filename
        filename = secure_filename(original_filename)
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        filename = f"{timestamp}_ai_{filename}"
        
        upload_folder = Path(current_app.config['UPLOAD_FOLDER'])
        upload_folder.mkdir(exist_ok=True)
        file_path = upload_folder / filename
        
        file.save(str(file_path))
        logger.info(f"AI processing file saved: {file_path}")
        
        # ä½¿ç”¨AIå¤„ç†å™¨
        processor = AIFileProcessor()
        result = processor.process_file_async_with_ai(file_path, original_filename, use_ai=True)
        
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        try:
            if result['success']:
                file_path.unlink()
        except Exception as e:
            logger.warning(f"Failed to remove temp file: {str(e)}")
        
        # è¿”å›ç»“æœ
        if result['success']:
            return jsonify({
                'success': True,
                'data': {
                    'upload_id': result['upload_id'],
                    'filename': original_filename,
                    'total_extracted': result.get('total_extracted', 0),
                    'total_saved': result.get('total_saved', 0),
                    'processing_time': result.get('processing_time', 0),
                    'processing_method': result.get('processing_method', 'ai'),
                    'ai_enabled': result.get('ai_enabled', True),
                    'statistics': result.get('statistics', {})
                },
                'message': result.get('message', 'AIå¤„ç†å®Œæˆ')
            }), 200
        else:
            return jsonify({
                'success': False,
                'error': {
                    'code': 'AI_PROCESSING_ERROR',
                    'message': 'AIå¤„ç†å¤±è´¥',
                    'details': result.get('error', 'æœªçŸ¥é”™è¯¯')
                }
            }), 400
            
    except Exception as e:
        logger.error(f"Upload file with AI error: {str(e)}")
        return jsonify({
            'success': False,
            'error': {
                'code': 'AI_UPLOAD_ERROR',
                'message': 'AIæ–‡ä»¶ä¸Šä¼ å¤±è´¥',
                'details': str(e)
            }
        }), 500


@upload_bp.route('/file/intelligent', methods=['POST'])
def upload_file_intelligent():
    """ä½¿ç”¨æ™ºèƒ½å¤„ç†å™¨ä¸Šä¼ å¹¶å¤„ç†æ–‡ä»¶
    å®ç°ç”¨æˆ·æè¿°çš„å®Œæ•´æµç¨‹ï¼šå¯¼å…¥ â†’ AIåˆ†æ â†’ è¿‡æ»¤æ— ç”¨å†…å®¹ â†’ æ•´ç†çŸ¥è¯†åº“
    """
    import asyncio
    
    async def process_intelligent():
        try:
            # æ£€æŸ¥æ–‡ä»¶
            if 'file' not in request.files:
                return jsonify({
                    'success': False,
                    'error': {
                        'code': 'NO_FILE',
                        'message': 'æœªé€‰æ‹©æ–‡ä»¶'
                    }
                }), 400
            
            file = request.files['file']
            if not file.filename:
                return jsonify({
                    'success': False,
                    'error': {
                        'code': 'EMPTY_FILENAME',
                        'message': 'æ–‡ä»¶åä¸ºç©º'
                    }
                }), 400
            
            # ä¿å­˜æ–‡ä»¶
            original_filename = file.filename
            filename = secure_filename(original_filename)
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            filename = f"{timestamp}_intelligent_{filename}"
            
            upload_folder = Path(current_app.config['UPLOAD_FOLDER'])
            upload_folder.mkdir(exist_ok=True)
            file_path = upload_folder / filename
            
            file.save(str(file_path))
            logger.info(f"Intelligent processing file saved: {file_path}")
            
            # è·å–å¤„ç†å‚æ•°
            force_ai = request.form.get('force_ai', 'false').lower() == 'true'
            
            # ä½¿ç”¨æ™ºèƒ½å¤„ç†å™¨
            try:
                result = await intelligent_file_processor.process_file_intelligently(
                    file_path, original_filename, force_ai=force_ai
                )
            except Exception as e:
                logger.error(f"Intelligent processing failed: {str(e)}")
                # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                try:
                    file_path.unlink()
                except:
                    pass
                
                return jsonify({
                    'success': False,
                    'error': {
                        'code': 'INTELLIGENT_PROCESSING_ERROR',
                        'message': 'æ™ºèƒ½å¤„ç†å¤±è´¥',
                        'details': str(e)
                    }
                }), 500
            
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            try:
                if result.success:
                    file_path.unlink()
                    logger.info(f"Cleaned up temp file: {file_path}")
            except Exception as e:
                logger.warning(f"Failed to remove temp file: {str(e)}")
            
            # è¿”å›ç»“æœ
            if result.success:
                return jsonify({
                    'success': True,
                    'data': {
                        'upload_id': result.upload_id,
                        'filename': result.filename,
                        'processing_summary': {
                            'original_messages': result.original_messages,
                            'useful_messages': result.useful_messages,
                            'noise_filtered': result.noise_filtered,
                            'qa_pairs_extracted': result.qa_pairs_extracted,
                            'final_knowledge_entries': result.final_knowledge_entries,
                            'content_quality_score': result.content_quality_score,
                            'extraction_efficiency': result.extraction_efficiency
                        },
                        'processing_performance': {
                            'processing_time': result.processing_time,
                            'ai_processing_time': result.ai_processing_time,
                            'processing_method': result.processing_method,
                            'ai_enabled': result.ai_enabled
                        },
                        'ai_usage': {
                            'ai_provider_used': result.ai_provider_used,
                            'tokens_consumed': result.tokens_consumed,
                            'processing_cost': result.processing_cost,
                            'content_improvement_rate': result.content_improvement_rate
                        },
                        'detailed_stats': result.detailed_stats
                    },
                    'message': f'ğŸ¤– æ™ºèƒ½å¤„ç†å®Œæˆ! ä» {result.original_messages} æ¡æ¶ˆæ¯ä¸­ç”Ÿæˆ {result.final_knowledge_entries} ä¸ªé«˜è´¨é‡çŸ¥è¯†åº“æ¡ç›®'
                }), 200
            else:
                return jsonify({
                    'success': False,
                    'error': {
                        'code': 'INTELLIGENT_PROCESSING_FAILED',
                        'message': 'æ™ºèƒ½å¤„ç†å¤±è´¥',
                        'details': result.error_message or 'æœªçŸ¥é”™è¯¯'
                    }
                }), 400
                
        except Exception as e:
            logger.error(f"Upload file with intelligent processing error: {str(e)}")
            return jsonify({
                'success': False,
                'error': {
                    'code': 'INTELLIGENT_UPLOAD_ERROR',
                    'message': 'æ™ºèƒ½æ–‡ä»¶ä¸Šä¼ å¤±è´¥',
                    'details': str(e)
                }
            }), 500
    
    # è¿è¡Œå¼‚æ­¥å¤„ç†
    return asyncio.run(process_intelligent())


@upload_bp.route('/file/async', methods=['POST'])
def upload_file_async():
    """å¼‚æ­¥æ–‡ä»¶ä¸Šä¼  - ä½¿ç”¨åå°ä»»åŠ¡é˜Ÿåˆ—å¤„ç†"""
    try:
        # æ£€æŸ¥æ–‡ä»¶
        if 'file' not in request.files:
            return jsonify({
                'success': False,
                'error': {
                    'code': 'NO_FILE',
                    'message': 'æœªé€‰æ‹©æ–‡ä»¶'
                }
            }), 400
        
        file = request.files['file']
        if not file.filename:
            return jsonify({
                'success': False,
                'error': {
                    'code': 'EMPTY_FILENAME',
                    'message': 'æ–‡ä»¶åä¸ºç©º'
                }
            }), 400
        
        # ä¿å­˜ä¸Šä¼ çš„æ–‡ä»¶
        original_filename = file.filename
        filename = secure_filename(original_filename)
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        filename = f"{timestamp}_async_{filename}"
        
        upload_folder = Path(current_app.config['UPLOAD_FOLDER'])
        upload_folder.mkdir(exist_ok=True)
        file_path = upload_folder / filename
        
        # ä¿å­˜æ–‡ä»¶
        file.save(str(file_path))
        logger.info(f"Async file saved: {file_path}")
        
        # è·å–å¤„ç†é€‰é¡¹
        priority_str = request.form.get('priority', 'normal').lower()
        priority_map = {
            'low': TaskPriority.LOW,
            'normal': TaskPriority.NORMAL,
            'high': TaskPriority.HIGH,
            'urgent': TaskPriority.URGENT
        }
        priority = priority_map.get(priority_str, TaskPriority.NORMAL)
        
        # æäº¤åˆ°åå°ä»»åŠ¡é˜Ÿåˆ—
        file_processing_service = get_file_processing_service()
        task_id = file_processing_service.process_file_async(
            file_path, original_filename, priority=priority
        )
        
        # è¿”å›ä»»åŠ¡IDï¼Œå®¢æˆ·ç«¯å¯ä»¥é€šè¿‡WebSocketç›‘å¬è¿›åº¦
        return jsonify({
            'success': True,
            'data': {
                'task_id': task_id,
                'filename': original_filename,
                'message': 'æ–‡ä»¶å·²æäº¤åå°å¤„ç†ï¼Œè¯·é€šè¿‡WebSocketç›‘å¬å¤„ç†è¿›åº¦'
            },
            'websocket_info': {
                'subscribe_event': 'subscribe_task',
                'task_id': task_id,
                'status_event': 'task_status_update'
            }
        }), 202
        
    except Exception as e:
        logger.error(f"Async upload error: {str(e)}")
        return jsonify({
            'success': False,
            'error': {
                'code': 'ASYNC_UPLOAD_ERROR',
                'message': 'å¼‚æ­¥æ–‡ä»¶ä¸Šä¼ å¤±è´¥',
                'details': str(e)
            }
        }), 500


@upload_bp.route('/task/<task_id>/status')
def get_task_status(task_id):
    """è·å–å¼‚æ­¥ä»»åŠ¡çŠ¶æ€"""
    try:
        file_processing_service = get_file_processing_service()
        status_data = file_processing_service.get_processing_status(task_id)
        
        if 'error' in status_data:
            return jsonify({
                'success': False,
                'error': {
                    'code': 'TASK_NOT_FOUND',
                    'message': status_data['error']
                }
            }), 404
        
        return jsonify({
            'success': True,
            'data': status_data,
            'message': 'ä»»åŠ¡çŠ¶æ€è·å–æˆåŠŸ'
        }), 200
        
    except Exception as e:
        logger.error(f"Get task status error: {str(e)}")
        return jsonify({
            'success': False,
            'error': {
                'code': 'TASK_STATUS_ERROR',
                'message': 'è·å–ä»»åŠ¡çŠ¶æ€å¤±è´¥',
                'details': str(e)
            }
        }), 500


@upload_bp.route('/queue/stats')
def get_queue_stats():
    """è·å–ä»»åŠ¡é˜Ÿåˆ—ç»Ÿè®¡ä¿¡æ¯"""
    try:
        from app.services.task_queue import get_task_queue
        task_queue = get_task_queue()
        stats = task_queue.get_queue_stats()
        
        return jsonify({
            'success': True,
            'data': stats,
            'message': 'é˜Ÿåˆ—ç»Ÿè®¡è·å–æˆåŠŸ'
        }), 200
        
    except Exception as e:
        logger.error(f"Get queue stats error: {str(e)}")
        return jsonify({
            'success': False,
            'error': {
                'code': 'QUEUE_STATS_ERROR',
                'message': 'è·å–é˜Ÿåˆ—ç»Ÿè®¡å¤±è´¥',
                'details': str(e)
            }
        }), 500


@upload_bp.route('/websocket/stats')
def get_websocket_stats():
    """è·å–WebSocketè¿æ¥ç»Ÿè®¡ä¿¡æ¯"""
    try:
        websocket_manager = get_websocket_manager()
        stats = websocket_manager.get_connection_stats()
        
        return jsonify({
            'success': True,
            'data': stats,
            'message': 'WebSocketç»Ÿè®¡è·å–æˆåŠŸ'
        }), 200
        
    except Exception as e:
        logger.error(f"Get WebSocket stats error: {str(e)}")
        return jsonify({
            'success': False,
            'error': {
                'code': 'WEBSOCKET_STATS_ERROR',
                'message': 'è·å–WebSocketç»Ÿè®¡å¤±è´¥',
                'details': str(e)
            }
        }), 500


@upload_bp.route('/task/<task_id>/cancel', methods=['POST'])
def cancel_task(task_id):
    """å–æ¶ˆå¼‚æ­¥ä»»åŠ¡"""
    try:
        from app.services.task_queue import get_task_queue
        task_queue = get_task_queue()
        
        success = task_queue.cancel_task(task_id)
        
        if success:
            # é€šçŸ¥WebSocketå®¢æˆ·ç«¯ä»»åŠ¡å·²å–æ¶ˆ
            websocket_manager = get_websocket_manager()
            websocket_manager.notify_task_update(task_id)
            
            return jsonify({
                'success': True,
                'data': {'task_id': task_id},
                'message': 'ä»»åŠ¡å·²å–æ¶ˆ'
            }), 200
        else:
            return jsonify({
                'success': False,
                'error': {
                    'code': 'CANCEL_FAILED',
                    'message': 'ä»»åŠ¡å–æ¶ˆå¤±è´¥ï¼Œå¯èƒ½æ­£åœ¨è¿è¡Œä¸­æˆ–å·²å®Œæˆ'
                }
            }), 400
        
    except Exception as e:
        logger.error(f"Cancel task error: {str(e)}")
        return jsonify({
            'success': False,
            'error': {
                'code': 'CANCEL_ERROR',
                'message': 'å–æ¶ˆä»»åŠ¡å¤±è´¥',
                'details': str(e)
            }
        }), 500